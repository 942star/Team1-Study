{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "캘리포니아 집값 예측.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkwpCzjFcNfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from sklearn.datasets import fetch_california_housing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uENCumjtcU0D",
        "colab_type": "code",
        "outputId": "18530000-e4d7-4804-ca52-594d87b6622d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = fetch_california_housing()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzCx8xprcUxU",
        "colab_type": "code",
        "outputId": "e3f3910b-b2ac-4eab-f472-d40a5653e9c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "data.data\n",
        "#Numpy array로 존재 해 있다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "          37.88      , -122.23      ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "          37.86      , -122.22      ],\n",
              "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "          37.85      , -122.24      ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "          39.43      , -121.22      ],\n",
              "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "          39.43      , -121.32      ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "          39.37      , -121.24      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMvKtyzYcUua",
        "colab_type": "code",
        "outputId": "1aa6a515-d44a-43b6-da0d-7ccdae86bde7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.data.shape\n",
        "#feature 가 8개인 data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20640, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRuvimQicrk9",
        "colab_type": "code",
        "outputId": "cc05a6c9-38a0-40d9-a92d-b6701dfa4f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "data.feature_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MedInc',\n",
              " 'HouseAge',\n",
              " 'AveRooms',\n",
              " 'AveBedrms',\n",
              " 'Population',\n",
              " 'AveOccup',\n",
              " 'Latitude',\n",
              " 'Longitude']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV39Xf8Wc1a3",
        "colab_type": "code",
        "outputId": "c1610b84-0e7b-46aa-e057-c5386148e464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUVEHabec1YL",
        "colab_type": "code",
        "outputId": "2e89d147-be7d-410e-bdb8-6f58346a024b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# the histogram of the data\n",
        "n, bins, patches = plt.hist(data.target, 50, density=True, facecolor='g', alpha=0.75)\n",
        "\n",
        "\n",
        "plt.xlabel('Housing value')\n",
        "plt.ylabel('Probability')\n",
        "#plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIElq/S/8oTcXnM0RPwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcn0P6pumErA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#정규분포를 따르지 않지만 out라이어 처럼 오른쪽 값이 확 올라와있음\n",
        "#그래서 정규분포로하면 오히려 성능이 저하되지 않을까 해서 \n",
        "#minmax로 하였음\n",
        "#이미지화(시각화)시킴으로써 어떤 정규화를 사용했을때 좋은 결과가 나오는지 유추할 수 있다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6qkwHcmc1Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = data.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDD__MvRc1R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm9XjJSHd4Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# testset을 만들기 위해서 random하게 split 하기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa_tEFMyeJNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input을 받아서 split하는 함수 (ex. x를 x_train, x_test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)\n",
        "# test랑 train의 데이터 비율을 나눌 때의 값 text_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEdnp7zTeD4R",
        "colab_type": "code",
        "outputId": "c3dfd2f4-d405-4352-f022-1553353c6d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape\n",
        "# 아까 20640개 에서 16512로 줄어든 것을 알 수 있다.\n",
        "# 즉 train set이 16512, 차가 test set이 됨"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16512, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83IUNKc9feJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW71gsz8feGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_, max_ = y_train.min(), y_train.max()\n",
        "y_train = (y_train - min_)/(max_-min_)\n",
        "# 무조건 0~1사이의 값으로 바꾸어 준다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uc-b5iNfeD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn 에서 class은 Pattern이 fit을 하고 transform하는 형태이다.\n",
        "# 그 객체네는 평균과 분산이 속성으로 들어가 있다.\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmT_96F_feAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgSeOSUqhaSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 방법1\n",
        "X_train = std_scaler.fit_transform(X_train)\n",
        "X_text = std_scaler.transform(X_test)\n",
        "#training data set을 이용하는 것임으로 fit가 아니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7CwDN2vfd91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#방법2\n",
        "std_scaler.fit(X_train)\n",
        "X_train = std_scaler.transform(X_train)\n",
        "\n",
        "#평균을 빼고 표준편차를 구해준다. -> 정규분포를 구함. (정규화)\n",
        "# X_train의 값을 정규화 해서 다시 X_train에 넣음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxsTmDs3hDKe",
        "colab_type": "code",
        "outputId": "11fefba4-f446-45e1-a929-a30e81a71588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "std_scaler.var_\n",
        "# feature가 8개 임으로 8개의 값을 보인다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.63677753e+00, 1.58320363e+02, 6.28741621e+00, 2.37004380e-01,\n",
              "       1.23260019e+06, 1.19518281e+02, 4.55271149e+00, 4.00840084e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU9Lw7JwhDGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 파이토치에서 사용할 수 있도록 DATASET을 만든다.\n",
        "#tensordataset : tensor들을 여러개 받아서 datset을 만든다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXXVGK4ChDCu",
        "colab_type": "code",
        "outputId": "10adf6c9-a6a6-4951-d2a5-82434e88f137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "X_train\n",
        "#Numpy array임으로 이것을 tensor로 바꾸어주어야한다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.45777205,  0.66678881, -0.11094855, ...,  0.05989871,\n",
              "        -0.81368326,  0.73705799],\n",
              "       [-0.65967019,  1.22311519, -0.84836844, ..., -0.02887541,\n",
              "         1.00943373, -1.31079267],\n",
              "       [-0.19769618, -1.4790415 ,  0.19991028, ..., -0.03110762,\n",
              "        -0.04038171, -0.56157902],\n",
              "       ...,\n",
              "       [-0.06387579,  1.30259039, -0.09983093, ...,  0.01255073,\n",
              "         0.98600035, -1.46063541],\n",
              "       [ 0.1159847 , -1.3995663 ,  0.14403719, ...,  0.01003022,\n",
              "        -0.86055002,  1.1266491 ],\n",
              "       [-1.14702392, -0.60481433, -0.75826274, ..., -0.00625122,\n",
              "        -1.352651  ,  1.23153901]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BmCDM68hC_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
        "X_test, y_test = torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
        "\n",
        "X_train, y_train = X_train.float(), y_train.float()\n",
        "X_test, y_test =X_test.float(), y_test.float()\n",
        "\n",
        "y_train, y_test =y_train.view(-1, 1), y_test.view(-1,1)\n",
        "#각각의 numpy array를 tensor로 만들어 주었다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n78apDGkbk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxYPKp6GkboT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB57q_Pbkbg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKsYDYdtkbc6",
        "colab_type": "code",
        "outputId": "21b27824-dd6d-4f45-c365-23239275c0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for batch_X, batch_y in train_loader:\n",
        "    print(batch_X)\n",
        "    print(batch_y)\n",
        "    break\n",
        "    #각 배치별로 x와 y를 받아 올 수 있다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.9914, -1.0022,  0.3865, -0.1184, -0.1639,  0.0146, -0.6918,  0.2975],\n",
            "        [ 0.0744,  1.1436, -0.1564,  0.0312, -0.1990, -0.0562, -0.7715,  0.5722],\n",
            "        [-0.1895,  0.8257,  0.2097, -0.1980, -1.0313, -0.0815,  0.9766, -1.2808],\n",
            "        [-0.8532, -0.9227, -0.6255, -0.0856,  0.1370, -0.0076, -1.4323,  1.2365],\n",
            "        [-0.4435,  1.1436, -0.3225, -0.0842,  0.1126,  0.0949, -0.7809,  0.6821],\n",
            "        [ 1.8998,  1.7000,  0.2786, -0.2237, -0.3620, -0.0842,  1.0329, -1.3208],\n",
            "        [-0.8663,  0.9847, -0.1080, -0.0899, -1.2294,  0.0463,  0.9391, -1.4207],\n",
            "        [-0.6912, -0.6843, -1.1420, -0.1087, -1.2285, -0.0067, -0.8699,  0.6721],\n",
            "        [ 0.7363,  0.5873,  0.3145, -0.0208, -0.5449, -0.0391,  0.9673, -1.4556],\n",
            "        [ 0.0705,  1.8589,  0.4452, -0.2425, -0.7169, -0.0708,  1.0141, -1.3058],\n",
            "        [-0.7117,  0.5078, -0.7817, -0.2685,  0.1757,  0.0197, -0.6731,  0.5672],\n",
            "        [-0.7002,  0.9847, -0.7162, -0.2575, -0.8565, -0.0681, -0.7621,  0.5523],\n",
            "        [-0.8823, -0.2074, -0.3608, -0.1300, -0.4161, -0.1179, -0.8746,  0.7470],\n",
            "        [-0.2003,  0.5078, -0.1883, -0.2954, -0.6340, -0.0176, -0.7293,  0.9668],\n",
            "        [ 1.0499, -0.9227,  0.0326, -0.1016,  0.2063,  0.0041,  0.8267, -1.1959],\n",
            "        [-0.3153, -0.3664, -0.2873, -0.0660,  1.1575,  0.0384, -0.6028,  0.2476],\n",
            "        [-0.7090, -1.5585,  0.1640,  0.0772, -0.5647, -0.0402,  1.2859, -0.5716],\n",
            "        [-0.7296, -0.6048, -0.9670, -0.0393, -0.5152,  0.0390, -0.7106,  0.6621],\n",
            "        [ 0.9760, -0.9227,  0.4049, -0.3611, -0.6899, -0.0609, -1.2167,  1.2565],\n",
            "        [-0.1948, -0.4459, -0.6812, -0.2331,  0.0190, -0.0283, -0.8840,  0.6372],\n",
            "        [-1.0705,  0.4284, -0.1299,  0.0634, -0.7187,  0.0709,  1.7452, -1.0561],\n",
            "        [-0.8279,  0.5078, -0.3087, -0.3369, -0.0558,  0.0218,  0.0674,  0.1627],\n",
            "        [-1.1263,  0.3489, -0.3649,  0.0830,  0.1000,  0.1482,  0.4611,  0.1327],\n",
            "        [ 3.2587,  1.8589,  0.8446, -0.2756, -0.6890, -0.0711,  1.0094, -1.4357],\n",
            "        [-0.3756,  1.0642, -0.4334, -0.1535, -0.5980,  0.0234, -0.7293,  0.7421],\n",
            "        [ 1.7808, -1.9559,  1.3690,  0.5081,  3.7651,  0.0216, -1.2261,  1.2116],\n",
            "        [-0.9843, -1.4790, -0.6051, -0.0507,  1.2809, -0.0056, -0.8652,  0.6422],\n",
            "        [-0.3342,  0.3489,  0.0125, -0.0419, -0.5476,  0.0207, -1.3058,  2.0007],\n",
            "        [-1.1002,  1.8589, -0.4287, -0.1782, -0.6791, -0.0814,  1.0891, -0.8613],\n",
            "        [-0.6120,  0.4284, -0.2617, -0.0677, -0.4233,  0.0476,  1.3516, -0.9412],\n",
            "        [-1.0145, -0.5253, -1.1194, -0.4051, -0.7656,  0.1670, -0.8137,  0.6771],\n",
            "        [ 0.6586, -0.9227,  0.3612, -0.1045, -0.2314, -0.0927, -0.9965,  0.9269]])\n",
            "tensor([[0.4666],\n",
            "        [0.5936],\n",
            "        [0.4204],\n",
            "        [0.2429],\n",
            "        [0.3115],\n",
            "        [0.5777],\n",
            "        [0.4072],\n",
            "        [0.6907],\n",
            "        [0.5623],\n",
            "        [0.5122],\n",
            "        [0.4342],\n",
            "        [0.8313],\n",
            "        [0.1495],\n",
            "        [0.2124],\n",
            "        [0.4959],\n",
            "        [0.3526],\n",
            "        [0.2932],\n",
            "        [0.3429],\n",
            "        [0.5423],\n",
            "        [0.3878],\n",
            "        [0.0990],\n",
            "        [0.1132],\n",
            "        [0.0763],\n",
            "        [1.0000],\n",
            "        [0.4192],\n",
            "        [0.8977],\n",
            "        [0.3101],\n",
            "        [0.0975],\n",
            "        [0.1699],\n",
            "        [0.1043],\n",
            "        [0.1720],\n",
            "        [0.6371]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XigxwoAeoaVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUyqXlzmkbYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 정의\n",
        "#괄호에는 상속으로 nn.Module이 들어가야한다.\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.input_dim=input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.linear1 = nn.Linear(self.input_dim, self.hidden_dim)\n",
        "       \n",
        "        #이것만 있으면 선형회기랑 같다.\n",
        "        self.linear2 = nn.Linear(self.hidden_dim , 1) # 예측 할 것이 집값 1개라서 그냥 1 \n",
        "        \n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        z1 = self.linear1(x)\n",
        "        a1 = torch.relu(z1)\n",
        "        #relu 함수 사용\n",
        "        z2 = self.linear2(a1)\n",
        "        a2 = torch.sigmoid(z2)\n",
        "        #시그모이드 함수 사용\n",
        "        return a2\n",
        "    \n",
        "# training set 중 일부를 벨리데이션 set으로 만들어서 벨리데이션 set이 어느 순간부터 증가하면 에폭을 멈추는 것\n",
        "# overfitting 을 방지하기 위해서\n",
        "# batch size도 모델에 영향을 미치지만 간단한 모델에서는 크게 영향을 끼치지 않는다.\n",
        "# 만약 모델 사이즈가 너무 크다면 gpu사이즈가 힘 닿을만큼 사이즈를 한다.\n",
        "\n",
        "# torch.optim.lrshceduler : 사람이 정한 이터레이션 마다 런닝 메이트를 조금씩 줄여나가는 것\n",
        "# 런닝메이트(얼마빠르게하는가)를 크게 키워서 모델을 빠르게 학습시키고 점점 모델을 미세 공정한다. \n",
        "\n",
        "# w1,w2 .. 등의 값을 너무 크지 않게 제약을 두는 것 : weighting-k\n",
        "# 아담 등의 옵티마이저를 정의 할때 같이 정의할 수 있다.\n",
        "# ooptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight = ..? )\n",
        "# weight를 너무 크게 주면 안된다 ! "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofm5fkOP27Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 선형회기 방식\n",
        "\n",
        "#괄호에는 상속으로 nn.Module이 들어가야한다.\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.input_dim=input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        \n",
        "        #이것만 있으면 선형회기랑 같다.\n",
        "        self.linear = nn.Linear(self.hidden_dim , 1) # 예측 할 것이 집값 1개라서 그냥 1 \n",
        "        \n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        z1 = self.linear1(x)\n",
        "        a1 = torch.relu(z1)\n",
        "        #relu 함수 사용\n",
        "        z2 = self.linear2(a1)\n",
        "        a2 = torch.sigmoid(z2)\n",
        "        #시그모이드 함수 사용\n",
        "        return a2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNmNj0mTpL2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device =torch.device('cuda')\n",
        "model =Model(8,32)\n",
        "# hidden_dim 32 \n",
        "# input은 feature 갯수 8\n",
        "\n",
        "#gpu메모리에 복사\n",
        "model = model.to(device)\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "# 아담이라는 optimzizer 사용 첫번쨰 인자에는 파라메타, 두번째 인자에는 learning mate? 를 넣는다.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FfpPicHp09D",
        "colab_type": "code",
        "outputId": "46329b5e-dca7-4de8-9bba-36e0ba410dde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "model.train()\n",
        "\n",
        "#batch x와 y사 cpu 메모리에 있음으로 gpu메모리에 복사해준다.\n",
        "\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        predict = model(batch_X)\n",
        "        # batch size 32임으로 32이일때 예측값이 predict에 저장된다.\n",
        "        loss = mse_loss(predict, batch_y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 200 == 0:\n",
        "            loss = loss.item()\n",
        "            \n",
        "            print(f\"{e}, {i} - {loss}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0, 0 - 0.09558461606502533\n",
            "0, 200 - 0.019482308998703957\n",
            "0, 400 - 0.024251705035567284\n",
            "1, 0 - 0.016049928963184357\n",
            "1, 200 - 0.028279073536396027\n",
            "1, 400 - 0.008484017103910446\n",
            "2, 0 - 0.025231709703803062\n",
            "2, 200 - 0.017426978796720505\n",
            "2, 400 - 0.010670489631593227\n",
            "3, 0 - 0.040613025426864624\n",
            "3, 200 - 0.01168146077543497\n",
            "3, 400 - 0.01779141277074814\n",
            "4, 0 - 0.013133348897099495\n",
            "4, 200 - 0.008591432124376297\n",
            "4, 400 - 0.023607507348060608\n",
            "5, 0 - 0.02564321830868721\n",
            "5, 200 - 0.01269567757844925\n",
            "5, 400 - 0.015616598539054394\n",
            "6, 0 - 0.0098111592233181\n",
            "6, 200 - 0.007288173772394657\n",
            "6, 400 - 0.0295658428221941\n",
            "7, 0 - 0.029280448332428932\n",
            "7, 200 - 0.006918889004737139\n",
            "7, 400 - 0.01703045889735222\n",
            "8, 0 - 0.009311925619840622\n",
            "8, 200 - 0.015845168381929398\n",
            "8, 400 - 0.009519509971141815\n",
            "9, 0 - 0.01441115327179432\n",
            "9, 200 - 0.01182837039232254\n",
            "9, 400 - 0.007242802530527115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qARo3uHhqjw8",
        "colab_type": "code",
        "outputId": "2db2aaa7-7a72-474d-fb48-ce1ae0da33d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#batch size를 32라고 정의했기 때문에\n",
        "for batch_X, batch_y in train_loader:\n",
        "    print(batch_X.shape)\n",
        "    print(batch_y.shape)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 8])\n",
            "torch.Size([32, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h0j9CgcqjtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 절대 값 한 것을 loss로 사용한다.\n",
        "#실제 예측값과 타깃값의 절대적인 차이를 구한다.\n",
        "l1_loss = nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJp8qknkqjpU",
        "colab_type": "code",
        "outputId": "a528fa37-3786-41f9-df0c-2a5a294b15c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# sample들의 loss의 총합을 구한다.\n",
        "# test dataset의 총갯수로 나누면 testdataset에 대한 전체적인 평균 값이 된다.\n",
        "\n",
        "#테스트 데이터 갯수 구하기\n",
        "test_num=0\n",
        "total_loss = []\n",
        "\n",
        "#테스트할떄 경사하강률을 구할 필요는 없음\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    \n",
        "    for batch_X, batch_y in test_loader:\n",
        "        #gpu 메모리에 복사한다.\n",
        "        batch_X, batch_y = batch_X.to(device) , batch_y.to(device)\n",
        "        \n",
        "        # training data set에 대해서 정규화 했기때문에 testset에 대해서도 정규화를 해줘야한다.\n",
        "  #      batch_X = (batch_X - std_scaler.mean_)/std_scaler.var_\n",
        "        predict = model(batch_X)\n",
        "        \n",
        "        \n",
        "        # predict 역변환\n",
        "        predict = (max_ - min_)*predict + min_\n",
        "        loss = l1_loss(predict, batch_y)\n",
        "        \n",
        "        #이 loss를 item으로 해서 cpu메모리에 옮겨준다.\n",
        "        loss = loss.item()\n",
        "        #이터레이션에 따른 평균\n",
        "        batch_size = batch_X.size(0)\n",
        "        #이터레이션 마다 shape이 다름\n",
        "        \n",
        "        total_loss.append(loss*batch_size)\n",
        "        test_num += batch_size\n",
        "        \n",
        "\n",
        "total_loss = np.sum(total_loss)/test_num\n",
        "print(total_loss)\n",
        "# testset, datasest 갯수가 8*98일때 32씩 나눴을때 2개가 남음. 결국 남은 2에대한 평균을 구하면 맞지않음으로\n",
        "# 갯수에 따른 가중치를 곱해줘야한다.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.9524874004513717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dhhRC6UvbyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch 32개의 데이터를 뽑아옴 32* 8\n",
        "# 32*8의 첫번째 값을 input으로 넣고\n",
        "#hidden demension을 32라고 했는데\n",
        "#batch_size와 hidden demension은 아줒 별개이다.\n",
        "#input demension과 feature의 갯수는 같아야함 -> 아니면 error 발생."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmIutYWWvbtr",
        "colab_type": "code",
        "outputId": "0c66019a-7126-4994-96f3-3de4739c7e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.linear1.weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-5.5243e-01, -4.3385e-01, -8.7458e-02,  2.7469e-01,  2.1158e-01,\n",
              "         -4.2903e-01, -1.5136e-01, -4.0116e-02],\n",
              "        [-1.6145e-01,  4.4096e-02,  1.4923e-01,  2.0162e-01, -2.1385e-03,\n",
              "          8.6848e-01,  3.3221e-01,  4.3321e-01],\n",
              "        [-1.3742e-02, -2.2131e-01,  1.0006e-02, -5.9139e-02,  1.3391e-01,\n",
              "          6.1100e-01, -6.9306e-02,  3.8332e-01],\n",
              "        [-1.6547e-01,  1.5930e-01,  1.0203e-01,  3.1954e-01,  1.4307e-01,\n",
              "         -1.8512e-01, -2.1390e-01,  3.2976e-01],\n",
              "        [-1.0420e-01, -6.5496e-03,  1.7713e-01, -1.7478e-01, -2.1677e-01,\n",
              "          5.0664e-01,  2.6011e-01,  3.8871e-01],\n",
              "        [-1.2301e-01,  3.1846e-01,  8.3581e-02,  3.7379e-01,  1.5673e-01,\n",
              "          5.9383e-01,  1.5557e-01,  1.6203e-02],\n",
              "        [-6.0477e-02,  7.2697e-02,  1.8711e-01, -7.2866e-02,  4.7935e-02,\n",
              "          3.5479e-01, -1.2179e-01,  1.6296e-01],\n",
              "        [ 1.3014e-01, -2.8421e-01,  9.5614e-02,  3.4909e-01, -3.1022e-01,\n",
              "         -1.6571e+00, -1.1292e-01, -6.9635e-02],\n",
              "        [ 1.9964e-01,  1.7128e-01, -1.8565e-02, -7.5180e-01,  1.0296e-01,\n",
              "          9.3823e-01,  3.8874e-01,  2.4459e-01],\n",
              "        [-1.1929e-01,  2.1564e-01, -2.0990e-01,  2.2601e-01, -2.4054e-01,\n",
              "         -4.7786e-01, -4.0160e-01,  8.6585e-02],\n",
              "        [ 5.7720e-02,  1.0600e-01, -8.9893e-04,  1.6993e-01, -2.8235e-05,\n",
              "          3.8219e-01,  3.9598e-01, -1.0376e-01],\n",
              "        [-6.7397e-03, -1.9047e-01, -2.8817e-01,  6.2124e-02, -4.2345e-01,\n",
              "          7.9601e-01,  3.3215e-01,  3.0245e-01],\n",
              "        [-3.3550e-02, -3.0595e-02,  1.0950e-01,  1.2672e-01,  2.1900e-03,\n",
              "          2.3506e-01,  5.4300e-01, -3.4725e-01],\n",
              "        [-1.5010e-01,  2.7794e-01,  2.0713e-01, -2.5072e-01,  8.9621e-02,\n",
              "          7.4428e-01,  4.4561e-02,  1.1328e-01],\n",
              "        [ 3.7045e-02,  2.0833e-01,  4.7544e-03, -4.1948e-01, -1.2248e-01,\n",
              "          5.4888e-01,  4.6120e-01,  4.7685e-01],\n",
              "        [-5.2064e-02, -6.5261e-02,  1.3796e-01,  7.3819e-02,  2.7676e-03,\n",
              "          3.8688e-02,  7.3545e-01, -1.7524e-01],\n",
              "        [-5.2009e-02,  1.3661e-01,  5.8809e-02,  3.5779e-01, -2.1306e-01,\n",
              "          3.9313e-01,  2.8719e-03,  1.9630e-01],\n",
              "        [-2.7754e-01,  1.3755e-01,  1.3611e-01, -4.3433e-01,  1.7654e-01,\n",
              "          2.4578e-01,  8.3246e-02,  5.8851e-01],\n",
              "        [ 2.7134e-01,  4.2159e-01,  4.2119e-01,  1.3196e-01, -1.8911e-03,\n",
              "         -6.7867e-01, -8.4457e-02, -2.1400e-01],\n",
              "        [ 3.5702e-01,  1.2983e-01,  1.1675e-01,  9.4939e-03,  1.7855e-01,\n",
              "         -1.8185e+00, -2.7931e-01, -1.2366e-01],\n",
              "        [-2.8565e-01, -7.3555e-02, -2.2014e-02,  8.6343e-02,  1.8156e-01,\n",
              "          3.8011e-01, -5.7796e-02,  4.9757e-01],\n",
              "        [ 3.3135e-01, -7.6047e-02,  4.7507e-01, -2.9292e-01, -1.5122e-01,\n",
              "         -1.0576e+00,  2.2934e-01, -5.4166e-01],\n",
              "        [ 2.5229e-01,  1.8414e-01, -2.8859e-01,  3.0404e-01,  2.5350e-01,\n",
              "         -2.2384e+00, -3.6792e-01, -3.3444e-01],\n",
              "        [ 1.4426e-01,  2.5758e-01, -1.2652e-01,  1.0378e-02,  9.7746e-02,\n",
              "         -2.3750e-01, -3.2757e-01,  1.5758e-01],\n",
              "        [ 2.0777e-01,  2.4405e-01,  2.1898e-01, -7.5224e-02,  1.8619e-01,\n",
              "         -3.7820e-01,  3.9694e-01, -5.4112e-01],\n",
              "        [-1.5722e-01, -2.3434e-01, -4.3378e-02,  2.3142e-01, -3.2091e-01,\n",
              "          1.4693e-01,  1.7865e-01, -9.8832e-02],\n",
              "        [-3.2615e-01, -4.0298e-02,  3.1752e-01,  4.7679e-02,  2.8329e-02,\n",
              "         -1.2079e-01,  3.8084e-01, -2.4713e-01],\n",
              "        [ 3.6637e-01,  1.6567e-01,  5.1921e-01, -1.0918e-01, -3.2751e-02,\n",
              "         -1.1788e+00, -4.2672e-01,  6.8343e-02],\n",
              "        [ 1.0701e-03, -4.1343e-01,  1.1518e-01, -8.3846e-01,  5.9376e-02,\n",
              "          2.5777e-01, -5.5421e-02,  4.2006e-01],\n",
              "        [ 4.7879e-01,  2.3443e-01, -1.7771e-01,  1.8116e-01, -7.9865e-02,\n",
              "         -2.2266e+00, -2.2582e-01, -3.0571e-01],\n",
              "        [ 1.2552e-01,  1.8821e-01, -3.8974e-01,  2.7241e-01, -6.0236e-02,\n",
              "         -1.7825e+00, -5.2179e-01, -4.9897e-01],\n",
              "        [-5.8201e-02, -3.7368e-01,  2.6015e-01, -1.4787e-01, -3.0562e-01,\n",
              "          5.7631e-01,  3.0548e-01, -6.7230e-02]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C55_7CLLvbp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBUSOfIIvbkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
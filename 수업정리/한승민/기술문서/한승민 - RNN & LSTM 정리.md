# NLP & Deep Learning
입력 시퀀스, 즉 순서가 중요한 문제에 딥러닝 모델을 사용한다.
NLP 관련 딥러닝을 보면 항상 문맥(시퀀스)이 중요한 문제에 적용한다.
언어생성(NLG) 따문에 딥러닝이 관심받는 것인데, 문맥이라는걸 고려한다는 것은 자연어 입력에 대해서 시퀀스대로 말을 붙여서 대답할 수 있다는 것이다.
그러나 아이러니하게 챗봇들은 딥러닝을 잘 안쓰는데, 검색 기반이 90%인게 현실이다.
> 후배 NC 자연어 연구소에 있는데 딥러닝 쓰긴하는데 언어 생성할때 어근/어간 뒤에 어떤 어미를 붙여야할까를 RNN 쓰더라
  NER 통해서 사용자의 의도를 파악하는 부분도 있고
  - 류선생님의 말씀


## RNN & LSTM
RNN만 알면 LSTM, Attention, Seq2Seq는 셀(cell) 연결만 조금 다를 뿐 다 구조는 같다.


RNN은 체인룰 때문에 시그모이드 계열을 쓰면 소수점을 계속 곱하므로 Gradient Vanishing 문제가 발생할 수 있다.
이러한 문제를 해결하기 위해서 LSTM이라는 모델이 등장하게 된다.
RNN은 노드에서 노드로 모든 w(weight)가 다 전달되는 방식이라면, LSTM은 셀을 구성해서 장기기억하고 단기기억하고 구분시키는 방식이다.
그러면 RNN은 t-2번째 input이 두 개의 w와 노드를 거쳐 t번째에 영향을 주는 구조지만, LSTM은 t-2번째에서 일부는 t-1로, 일부는 잊고, 일부는 다이렉트로 t-1로 간다.
즉, NLP 관점에서 보면 '할 수 있다'라고하는 세 단어를 학습한다고 했을 때 RNN은 시퀀스를 그대로 유지해야 하고('할 -> 수' / '수 -> 있다'가 나오도록 학습해야 하고)
이렇게 되면 당연히 시퀀스가 길수록 w가 점점 희미해질 수 밖에 없다.
LSTM은 '할 -> 수'에서 w가 한개가 아니라 잊을지, 단기기억 시킬지, 장기기억 시킬지를 각각 w를 줘서 최종적으로 합쳐진 w가 나가는 구조이다.
LSTM의 기본 구조는 RNN 구조이기 때문에 다 같은 계열 모델들 노드에서 다음 노드로 나갈때 어떻게 w를 설계할 것이냐가 관건이다.


LSTM을 좀 더 자세히 설명해보자면 예를 들어, a-b-c의 시퀀스인데 실제 중요한 시퀀스는 a-(b)-c 일 수도 있으니 w를 조절하는 방법이 LSTM이다.

![Figure](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/14b4127ef56f57eab19bb48d80ec169e7b1be944/3-Figure2-1.png)

위 그림을 살펴보면 이전 인풋을 relu로 바로 다음 output으로 보내는 부분이 셀에 존재한다.
다시 앞서 설명한 예시를 적용해보았을 때 결국 a-b-c가 아니라 a-c가 된다.

![Figure2](http://i.imgur.com/jKodJ1u.png)

RNN은 모든 이전 입력 시퀀스가 다음으로 가는 구조이지만 하이퍼볼릭 이라서 나중에 역전파하면 엄청 작은 값이 나올 수 있다.
LSTM은 w가 여러 가지이며, 위 그림을 살펴보면 `+`로 표시 되어있는데 그럼 누구의 영향력이 크냐에 따라서 w가 바뀌는 것이다.
즉, Long-Term에서 이전 입력값을 쓸지 말지를 기억하는 것이다.


## Word Embedding
주변단어로 중심단어를 예측하는 방식은 기존 NN의 단순화된 버전이다.
Word Embedding부터 나오는 딥러닝은 순서도 고려하겠다는 의미이다.
RNN은 시퀀스 정보를 유지하기 위한 모델이고 CNN, RNN 둘다 입력에 Word Embedding이 들어가는데, 심볼(symbol)을 인풋으로 넣을 수 없기 때문이다.
심볼을 백터로 변환해서 넣어주는데 입력단 노드 수만큼 그때 문맥을 고려해서 백터화 하겠다는게 Word Embedding이고 순서를 고려하지 않는다면 분포만 사용한다.

Word Embedding은 정확히 이야기하면 ann도 아니고 아주 단순화된 버전이다.
원 논문을 보면 입력 노드들(주변단어)의 선형합을 소프트맥스 하는 네트워크라서 히든도 없고 임베딩이 필요한 이유는 의미적(문맥적)으로 비슷한 애들이 비슷한 벡터표현을 갖도록 만들어주는 과정에 불과하다.
왜냐하면 CNN, RNN같은 모델들 input에 임배딩된(의미적으로 유사한 벡터 표현) w를 곱할 것이기 때문이다.
Word Embedding은 쉽게 말해 input을 표현하는 과정일 뿐이며, 나머진 그냥 어떻게 시퀀스가 유지되는지 모델로만 봐야한다.


## Word2Vec
Word2Vec에서는 일반적인 NN와는 조금 다르다.
보통은 accuracy를 측정하면서 원하는 output이 나오도록 Overfitting이 되더라도 학습하는 것이고,
Word2Vec은 학습이 잘 안되더라도 만드는 과정에서 달라지는 w를 통해 비슷한 단어가 비슷한 벡터표현을 갖도록 인코딩 하는 과정이다.

## Explainable Model에 대해서
explainable deep learning model -> w를 설명하는 방법, 즉 w를 해석해야 설명 가능한 모델이다.

합성곱의 결과가 시각적인 특징점이니깐 이런 점들 때문에 모델이나 결과가 이렇다가 되는데 nlp는 또 다르다. 설명이 안된다.
그래서 구글은 버트를 만들때 어간을 최대한 많이 찾아서 프리 트레인 시켜넣은 것이고, 그것이 중요한 점이다.
모델도 중요하긴 하지만 이미 피처를 잘 정의해놓은 것이다.